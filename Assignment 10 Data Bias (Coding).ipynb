{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed934a6",
   "metadata": {},
   "source": [
    "# Assignment: Bias and Fairness Assessment of Models \n",
    "\n",
    "## Anoosha Valliani\n",
    "\n",
    "### Deadline: 03/31/2023 \n",
    "\n",
    "### TOTAL POINTS : 10 \n",
    "\n",
    "The goal of this assignment is to explore the concept of bias through querying an existing natural language processing model — specifically, the Perspective API released by Google Jigsaw. For this assignment, you will need to examine a dataset of internet comments and their scores, in addition to formulating your own queries and using the Perspective API client to score the toxicity of each comment.\n",
    "\n",
    "Content warning: the Perspective API is designed for use in content moderation, and the dataset contained very “toxic” comments. Some of the comments in this dataset are racist, sexist, ableist, and offensive. Some comments contain profane language. If you are uncomfortable with exposure to these comments in the manner of this assignment, please let me know by 03/24/2023 and we will work on finding an alternative approach.\n",
    "\n",
    "Documentation for the Perspective API can be found hereLinks to an external site..\n",
    "\n",
    " \n",
    "\n",
    "## Step 1: Set up a Perspective API key\n",
    "\n",
    "In order to access the Perspective API, you will need to register. First, create a Google Cloud account at console.cloud.google.comLinks to an external site. (we do not need to use any billing services for this project). Then, follow the instructions hereLinks to an external site.. Once you receive a confirmation email, you will be able to find a unique API key in the Credentials tab of your Google Cloud console.\n",
    "\n",
    " \n",
    "\n",
    "## Step 2: Explore the sample dataset to form hypotheses\n",
    "\n",
    "Download the CSV file from Canvas (under Canvas->Files->Data_Bias_Assignment->Sample_labaled_data.csvand open them in your preferred app (e.g., Excel, Jupyter etc). Examine the labels assigned by manual reviewers. You may wish to do some data parsing to find out things like the most common words used in comments where toxicity was present. Visual inspection of the comments may spark some ideas for how to test the API for potential biases. \n",
    "\n",
    " \n",
    "\n",
    "## Step 3: Form hypotheses, Design and perform tests [4 MARKS]\n",
    "\n",
    "Decide how you would like to test the Perspective model for bias. Document your methods, all queries that you make to the API, and all scores received in a Jupyter notebook. \n",
    "\n",
    "There are plenty of different things you could examine in the data exploration step, but one thing that you will most likely want to do is determine a threshold for the model, or the point x at which scores above x are considered toxic or abusive. Take a few examples from the sample data provided and determine the threshold. Setting a good threshold is important for the later steps. \n",
    "For the testing step, you should develop a hypothesis about Perspective’s performance based on your understanding of how the API is trained and used. Whether or not your hypothesis is correct will have no bearing on your grade. Example hypotheses could be that Perspective will make more mistakes on shorter or more informal pieces of content (like tweets), that Perspective will be less likely to mark anti-male content as toxic when compared to anti-female content, or that Perspective will fail if we replace the most common swear words with less common obscenities. You will then develop your own (small) test set of N example comments, document the model scores, and assess whether or not your hypothesis was correct based on your sample. These examples may be freshly written by you or downloaded from the internet or even copied from the sample data provided.\n",
    "Your tests do not need to be extensive or exhaustive; an N of low double digits is fine. However, we know that the larger the number of examples, the more accurate we are in our estimates of Perspective’s performance. How does a low sample size impact your results, and the conclusions we can draw from them?\n",
    " \n",
    "\n",
    "## Step 4: Write about your results [4 MARKS]\n",
    "\n",
    "Write a few paragraphs, either in the README or in the notebook, reflecting on what you have learned, what you found, what (if anything) surprised you about your findings, and/or what theories you have about why any biases might exist, if you find they exist. You can also include any questions this assignment raised for you about bias or machine learning. Questions you may wish to answer include:\n",
    "\n",
    "What biases do you think might exist in the model based on intuitions or public documentation about how the model was created?\n",
    "What were your results?\n",
    "What theories do you have about why your results are what they are?\n",
    "\n",
    "## Step 5: Publication and submission [2 MARKS] \n",
    "\n",
    "Create a GitHub repository and upload your code. Add a README and a LICENSE for the repo. The README should include all of your documentation about your analysis (what you are testing, your hypotheses, and your results). The LICENSE should be an MIT LicenseLinks to an external site. for your code.\n",
    "\n",
    "On Canvas, submit a link to your GitHub repo, which should contain your code, your test example comments submitted to the API along with their scores (in csv preferably), a README and a LICENSE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6dfd4",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "The Perspective API will accuse comments that are not toxic of being toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f65ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                id  \\\n",
      "0               5  0001ea8717f6de06   \n",
      "1               7  000247e83dcc1211   \n",
      "2              11  0002f87b16116a7f   \n",
      "3              13  0003e1cccfd5a40a   \n",
      "4              14  00059ace3e3e9a53   \n",
      "...           ...               ...   \n",
      "55247      153147  fff83b80284d8440   \n",
      "55248      153149  fff8f521a7dbcd47   \n",
      "55249      153150  fff8f64043129fa2   \n",
      "55250      153151  fff9d70fe0722906   \n",
      "55251      153154  fffa8a11c4378854   \n",
      "\n",
      "                                            comment_text toxic  \n",
      "0      Thank you for understanding I think very highl...    no  \n",
      "1                         Dear god this site is horrible    no  \n",
      "2       Somebody will invariably try to add Religion ...    no  \n",
      "3        It says it right there that it IS a type The...    no  \n",
      "4         Before adding a new product to the list mak...    no  \n",
      "...                                                  ...   ...  \n",
      "55247  Consensus for ruining Wikipedia I think that c...    no  \n",
      "55248  shut down the mexican border withought looking...    no  \n",
      "55249  Jerome I see you never got around to this… I’m...    no  \n",
      "55250  Lucky bastard  httpwikimediafoundationorgwikiP...    no  \n",
      "55251  shame on you all  You want to speak about gays...    no  \n",
      "\n",
      "[55252 rows x 4 columns]\n",
      "no     51409\n",
      "yes     3843\n",
      "Name: toxic, dtype: int64\n",
      "[('a', 3581), ('the', 3369), ('you', 3320), ('is', 3173), ('and', 2270), ('to', 2248), ('i', 2119), ('of', 1564), ('nigger', 1467), ('are', 1302), ('that', 1115), ('faggot', 1049), ('this', 1011), ('boob', 1001), ('poop', 987), ('it', 986), ('hate', 955), ('gay', 941), ('in', 902), ('your', 891), ('youi', 886), ('niggers', 884), ('my', 815), ('on', 711), ('not', 665), ('penis', 624), ('stupid', 618), ('for', 595), ('die', 595), ('balls', 555), ('be', 527), ('so', 520), ('all', 520), ('with', 513), ('bitch', 512), ('like', 507), ('ღ', 504), ('have', 498), ('kill', 494), ('must', 486), ('vandal', 469), ('me', 458), ('anal', 455), ('traitor', 447), ('diefuk', 444), ('what', 442), ('shit', 432), ('sucks', 432), ('niggerjew', 424), ('he', 415), ('willy', 412), ('cunt', 410), ('as', 407), ('was', 403), ('an', 398), ('just', 386), ('if', 385), ('suck', 384), ('pleasenigga', 384), ('u', 382), ('up', 382), ('fag', 380), ('but', 378), ('dont', 373), ('c', 370), ('e', 369), ('m', 364), ('im', 362), ('or', 352), ('analanal', 351), ('bums', 350), ('do', 342), ('its', 340), ('am', 325), ('they', 320), ('who', 318), ('about', 314), ('yourself', 304), ('no', 296), ('will', 293), ('page', 290), ('from', 287), ('people', 279), ('curps', 269), ('small', 261), ('know', 251), ('can', 250), ('article', 241), ('why', 236), ('one', 229), ('goddned', 226), ('idiot', 223), ('sucksusa', 223), ('by', 221), ('france', 221), ('there', 219), ('fgtyou', 219), ('his', 217), ('think', 216), ('r', 216), ('ballsballs', 215), ('she', 214), ('get', 213), ('at', 213), ('f', 213), ('wikipedia', 211), ('going', 209), ('fat', 209), ('should', 208), ('we', 206), ('how', 201), ('rules', 199), ('sex', 196), ('k', 196), ('has', 195), ('because', 195), ('off', 191), ('o', 191), ('anime', 188), ('comedy', 186), ('go', 184), ('youre', 184), ('faggotgay', 184), ('pelican', 179), ('some', 175), ('hornyhorny', 174), ('wheels', 174), ('ballz', 173), ('oxymoron83', 172), ('now', 165), ('here', 164), ('shut', 162), ('would', 159), ('when', 159), ('name', 157), ('really', 151), ('little', 149), ('stop', 149), ('out', 148), ('likes', 148), ('were', 147), ('more', 146), ('dead', 145), ('hell', 144), ('only', 143), ('then', 142), ('say', 136), ('them', 136), ('please', 132), ('want', 131), ('her', 130), ('did', 127), ('big', 126), ('make', 125), ('see', 125), ('even', 124), ('also', 123), ('other', 123), ('babies', 123), ('nigggers', 123), ('time', 122), ('being', 122), ('him', 122), ('peniscockuser', 120), ('couple', 119), ('very', 118), ('any', 118), ('crap', 117), ('their', 117), ('well', 114), ('thats', 114), ('been', 113), ('neiln', 112), ('nthep', 111), ('cocksuckers', 111), ('ok', 108), ('cant', 107), ('does', 107), ('man', 106), ('right', 105), ('edit', 104), ('had', 100), ('someone', 99), ('than', 99), ('idiots', 98), ('lick', 98), ('good', 96), ('life', 96), ('which', 93), ('bastard', 93), ('such', 91), ('talk', 91), ('too', 90), ('take', 90), ('sad', 90), ('way', 88), ('tiny', 88), ('never', 86), ('rip', 86), ('sexy', 86), ('lol', 84), ('again', 83), ('something', 83), ('down', 83), ('decapitate', 83), ('ever', 82), ('bullshit', 81), ('death', 81), ('made', 79), ('over', 79), ('love', 79), ('damn', 78), ('got', 78), ('thing', 77), ('need', 76), ('person', 76), ('could', 74), ('look', 74), ('antandrus', 73), ('back', 73), ('these', 72), ('first', 71), ('shitonly', 71), ('guy', 71), ('block', 71), ('hope', 70), ('world', 70), ('lonely', 70), ('said', 69), ('call', 69), ('read', 69), ('tbloeme', 69), ('hes', 68), ('isnt', 68), ('dumb', 68), ('nazihi', 68), ('ha', 67), ('much', 66), ('delete', 66), ('slice', 66), ('mean', 65), ('nothing', 65), ('use', 65), ('wants', 64), ('anyone', 63), ('oh', 63), ('better', 63), ('most', 62), ('where', 61), ('put', 61), ('ill', 61), ('before', 59), ('fact', 59), ('come', 59), ('old', 58), ('many', 58), ('ive', 58), ('vandalism', 58), ('doesnt', 58), ('cjcurrie', 58), ('real', 57), ('own', 57), ('edits', 57), ('every', 57), ('himself', 57), ('us', 56), ('those', 56), ('twat', 55), ('wrong', 55), ('blocked', 55), ('into', 55), ('gilliam', 55), ('wikipedo', 55), ('racist', 54), ('bad', 54), ('cock', 54), ('bloody', 54), ('give', 53), ('moron', 53), ('another', 53), ('fagcjcurrie', 53), ('gayfrance', 53), ('long', 52), ('black', 52), ('sorry', 52), ('homo', 52), ('thanks', 51), ('hey', 51), ('anything', 51), ('god', 50), ('whore', 50), ('believe', 50), ('same', 50), ('didnt', 50), ('word', 49), ('still', 49), ('text', 49), ('ball', 48), ('guys', 48), ('actually', 47), ('try', 47), ('keep', 47), ('new', 46), ('trying', 46), ('ridiculous', 46), ('yes', 46), ('mouth', 45), ('retarded', 45), ('loser', 45), ('after', 45), ('2', 44), ('around', 44), ('smart', 44), ('sweaty', 44), ('called', 44), ('things', 44), ('head', 44), ('find', 44), ('idiotic', 44), ('reason', 43), ('articles', 43), ('nice', 43), ('already', 43), ('best', 43), ('source', 43), ('bummer', 43), ('piece', 42), ('show', 42), ('comment', 42), ('ur', 42), ('making', 42), ('silly', 41), ('change', 41), ('sure', 41), ('used', 41), ('school', 41), ('womens', 41), ('always', 40), ('jerk', 40), ('our', 40), ('fool', 40), ('let', 40), ('woman', 39), ('write', 39), ('information', 39), ('makes', 39), ('hi', 39), ('face', 39), ('while', 39), ('away', 39), ('lying', 39), ('mother', 39), ('may', 38), ('place', 38), ('rape', 38), ('wow', 38), ('tell', 38), ('site', 38), ('editing', 38), ('day', 38), ('link', 38), ('list', 38), ('kind', 37), ('history', 37), ('since', 37), ('last', 37), ('talking', 37), ('point', 37), ('added', 37), ('butt', 37), ('white', 37), ('saying', 37), ('eat', 37), ('section', 37), ('problem', 37), ('care', 37), ('doing', 36), ('live', 36), ('looks', 36), ('user', 36), ('against', 36), ('vagina', 36), ('dude', 36), ('har', 36), ('comments', 35), ('else', 35), ('everyone', 35), ('mom', 35), ('stuff', 35), ('lot', 35), ('case', 35), ('arrsephuck', 35), ('broom', 35), ('arrse', 35), ('blooody', 35), ('personal', 34), ('maybe', 34), ('wont', 34), ('ugly', 34), ('wiki', 34), ('having', 34), ('admin', 34), ('sources', 34), ('needs', 34), ('probably', 33), ('nigga', 33), ('s', 33), ('work', 33), ('pages', 33), ('sack', 33), ('remove', 33), ('poor', 32), ('post', 32), ('feel', 32), ('stupidity', 32), ('agree', 32), ('worthless', 32), ('add', 32), ('says', 32), ('porn', 32), ('two', 32), ('utc', 32), ('freakyou', 32), ('killed', 31), ('true', 31), ('truth', 31), ('bit', 31), ('ignorant', 31), ('heard', 31), ('id', 31), ('simply', 31), ('help', 31), ('1', 31), ('though', 30), ('end', 30), ('removed', 30), ('enough', 30), ('complete', 30), ('girl', 30), ('theres', 30), ('men', 30), ('testicles', 30), ('sick', 29), ('encyclopedia', 29), ('calling', 29), ('thought', 29), ('ip', 29), ('facts', 29), ('question', 29), ('deleted', 28), ('looking', 28), ('either', 28), ('done', 28), ('means', 28), ('both', 28), ('jews', 28), ('different', 28), ('number', 28), ('boy', 27), ('next', 27), ('yet', 27), ('raped', 27), ('picture', 27), ('garbage', 27), ('matter', 27), ('full', 27), ('haha', 27), ('d', 27), ('war', 27), ('opinion', 27), ('yeah', 27), ('getting', 27), ('brianwashing', 27), ('sonofa', 27), ('wrote', 26), ('years', 26), ('women', 26), ('quite', 26), ('seems', 26), ('understand', 26), ('english', 26), ('3', 26), ('gonna', 26), ('discussion', 26), ('retard', 26), ('others', 26), ('seen', 26), ('ones', 26), ('blah', 26), ('lo', 26), ('given', 25), ('bunch', 25), ('nonsense', 25), ('pathetic', 25), ('queer', 25), ('wtf', 25), ('thank', 25), ('editors', 25), ('using', 25), ('course', 25), ('everything', 25), ('obviously', 25), ('idea', 25), ('anyway', 25), ('knows', 25), ('children', 25), ('gets', 25), ('without', 25), ('evidence', 25), ('smack', 25), ('whole', 24), ('attack', 24), ('instead', 24), ('words', 24), ('become', 24), ('request', 24), ('until', 24), ('pussy', 24), ('anus', 24), ('nazi', 23), ('father', 23), ('soon', 23), ('mind', 23), ('rubbish', 23), ('human', 23), ('hard', 23), ('seriously', 23), ('play', 23), ('hello', 23), ('country', 23), ('statement', 23), ('rather', 23), ('learn', 23), ('friend', 23), ('common', 23), ('christian', 23), ('wanted', 23), ('deleting', 23), ('whats', 23), ('clearly', 23), ('sacks', 23), ('headline', 22), ('ya', 22), ('great', 22), ('support', 22), ('b', 22), ('game', 22), ('website', 22), ('guess', 22), ('fun', 22), ('rights', 22), ('year', 22), ('account', 22), ('funny', 22), ('comes', 22), ('cleaning', 22), ('shes', 21), ('times', 21), ('least', 21), ('part', 21), ('trash', 21), ('stay', 21), ('cool', 21), ('juicy', 21), ('start', 21), ('youve', 21), ('pov', 21), ('ask', 21), ('whatever', 21), ('band', 21), ('less', 21), ('wanna', 21), ('went', 21), ('eats', 21), ('internet', 21), ('free', 21), ('broke', 21), ('israelsvgflag', 21), ('throat', 21), ('fake', 20), ('fuk', 20), ('troll', 20), ('putting', 20), ('friends', 20), ('reading', 20), ('sockpuppet', 20), ('sweet', 20), ('monkey', 20), ('high', 20), ('above', 20), ('dirty', 20), ('known', 20), ('theyre', 20), ('wasnt', 20), ('kids', 20), ('far', 20), ('liar', 20), ('second', 20), ('son', 20), ('found', 20), ('sense', 20), ('yo', 20), ('wikipedians', 20), ('music', 20), ('lets', 20), ('crazy', 20), ('poo', 20), ('goodbye', 20), ('clams', 20), ('erybody', 20), ('quote', 19), ('obvious', 19), ('huge', 19), ('arent', 19), ('under', 19), ('piss', 19), ('joke', 19), ('sexual', 19), ('living', 19), ('once', 19), ('listen', 19), ('fix', 19), ('homosexual', 19), ('total', 19), ('especially', 19), ('left', 19), ('book', 19), ('leave', 19), ('4', 19), ('muslims', 19), ('unblock', 19), ('failed', 19), ('wouldnt', 19), ('throw', 19), ('research', 18), ('fools', 18), ('banned', 18), ('power', 18), ('bot', 18), ('myself', 18), ('mention', 18), ('taking', 18), ('re', 18), ('correct', 18), ('disgusting', 18), ('t', 18), ('nobody', 18), ('nerd', 18), ('completely', 18), ('reference', 18), ('cannot', 18), ('child', 18), ('taken', 18), ('havent', 18), ('n', 18), ('sit', 18), ('size', 18), ('message', 18), ('obama', 18), ('job', 18), ('lovers', 18), ('watch', 17), ('earth', 17), ('y', 17), ('days', 17), ('baby', 17), ('continue', 17), ('mr', 17), ('shows', 17), ('perhaps', 17), ('jew', 17), ('suggest', 17), ('gives', 17), ('smell', 17), ('faggots', 17), ('reliable', 17), ('killing', 17), ('pretty', 17), ('took', 17), ('wank', 17), ('young', 17), ('speak', 17), ('through', 17), ('might', 17), ('bitches', 17), ('stick', 17), ('check', 17), ('john', 17), ('2486789807', 17), ('burn', 16), ('america', 16), ('cause', 16), ('evil', 16), ('scum', 16), ('fags', 16), ('removing', 16), ('ago', 16), ('few', 16), ('boys', 16), ('noticed', 16), ('night', 16), ('run', 16), ('youll', 16), ('image', 16), ('deserve', 16), ('language', 16), ('brain', 16), ('written', 16), ('insult', 16), ('beat', 16), ('writing', 16), ('jewish', 16), ('muslim', 16), ('cuz', 16), ('example', 16), ('american', 16), ('alone', 16), ('unless', 16), ('original', 16), ('future', 16), ('super', 16), ('totally', 16), ('money', 16), ('vandalize', 15), ('horrible', 15), ('today', 15), ('cancer', 15), ('cut', 15), ('sign', 15), ('editor', 15), ('boobs', 15), ('consider', 15), ('pictures', 15), ('shouldnt', 15), ('reverted', 15), ('claim', 15), ('open', 15), ('adding', 15), ('info', 15), ('between', 15), ('entire', 15), ('three', 15), ('mentioned', 15), ('hitler', 15), ('cum', 15), ('fck', 15), ('useless', 15), ('chinese', 15), ('story', 15), ('blood', 15), ('content', 15), ('awesome', 15), ('allowed', 15), ('etc', 15), ('lives', 15), ('gays', 15), ('indian', 15), ('hctibstidedoogymodnutnod', 15), ('fart', 15), ('ging', 15), ('horsecock', 15), ('jamed', 15), ('esanchez7587', 15), ('random', 14), ('simple', 14), ('sometimes', 14), ('respect', 14), ('morons', 14), ('vandalizing', 14), ('p', 14), ('biased', 14), ('dog', 14), ('behind', 14), ('rule', 14), ('preceding', 14), ('retards', 14), ('thinking', 14), ('references', 14), ('president', 14), ('absolutely', 14), ('admins', 14), ('culture', 14), ('btw', 14), ('sock', 14), ('shall', 14), ('girls', 14), ('bet', 14), ('fine', 14), ('pig', 14), ('cares', 14), ('doubt', 14), ('grow', 14), ('usa', 14), ('state', 14), ('whether', 14), ('standard', 14), ('color', 14), ('computer', 14), ('meaning', 14), ('exist', 14), ('wait', 14), ('aint', 14), ('order', 14), ('daki122', 14), ('pricks', 14), ('important', 14), ('deal', 14), ('race', 14), ('thinks', 13), ('hot', 13), ('foolish', 13), ('revert', 13), ('created', 13), ('yours', 13), ('act', 13), ('changes', 13), ('pile', 13), ('fire', 13), ('penises', 13), ('current', 13), ('semiprotected', 13), ('screw', 13), ('omg', 13), ('seem', 13), ('jesus', 13), ('came', 13), ('хунта', 13), ('states', 13), ('freedoms', 13), ('liberties', 13), ('party', 13), ('remember', 13), ('prove', 13), ('actual', 13), ('report', 13), ('move', 13), ('enjoy', 13), ('indeed', 13), ('slut', 13), ('brown', 13), ('nation', 13), ('offensive', 13), ('considered', 13), ('false', 13), ('mine', 13), ('single', 13), ('rid', 13), ('british', 13), ('2015', 13), ('5', 13), ('yur', 13), ('hctibstidedoogymodnutnodpenis', 13), ('dare', 12), ('self', 12), ('bold', 12), ('reasons', 12), ('ban', 12), ('dies', 12), ('otherwise', 12), ('wish', 12), ('side', 12), ('almost', 12), ('images', 12), ('deletion', 12), ('wonder', 12), ('unsigned', 12), ('sounds', 12), ('racism', 12), ('fk', 12), ('sucking', 12), ('hurt', 12), ('anybody', 12), ('rude', 12), ('apparently', 12), ('oral', 12), ('hates', 12), ('fair', 12), ('tits', 12), ('movie', 12), ('somebody', 12), ('touch', 12), ('wife', 12), ('changing', 12), ('ignorance', 12), ('tired', 12), ('term', 12), ('lost', 12), ('middle', 12), ('singing', 12), ('billion', 12), ('hand', 12), ('lies', 12), ('saw', 12), ('behavior', 12), ('based', 12), ('biggest', 12), ('happy', 12), ('proof', 12), ('yall', 12), ('whom', 12), ('posting', 12), ('wp', 12), ('valid', 12), ('hole', 12), ('car', 12), ('policy', 12), ('trolling', 12), ('top', 12), ('bring', 12), ('absolute', 12), ('10', 12), ('master', 12), ('shitty', 12), ('gave', 12), ('utter', 12), ('rapping', 12), ('gaythis', 12), ('aidsqueer', 12), ('arabs', 11), ('europe', 11), ('arrogant', 11), ('islam', 11), ('claims', 11), ('americans', 11), ('worst', 11), ('usually', 11), ('freak', 11), ('worse', 11), ('cunts', 11), ('itself', 11), ('cocks', 11), ('song', 11), ('ps', 11), ('quit', 11), ('murder', 11), ('note', 11), ('tried', 11), ('sir', 11), ('jerks', 11), ('media', 11), ('particular', 11), ('coming', 11), ('gone', 11), ('subject', 11), ('happen', 11), ('breasts', 11), ('kidding', 11), ('nasty', 11), ('lack', 11), ('address', 11), ('brother', 11), ('w', 11), ('sentence', 11), ('sam', 11), ('lesbian', 11), ('stated', 11), ('horny', 11), ('included', 11), ('king', 11), ('company', 11), ('junk', 11), ('pay', 11), ('title', 11), ('everybody', 11), ('turn', 11), ('jk', 11), ('however', 11), ('amount', 11), ('moronic', 11), ('reverting', 11), ('users', 11), ('looked', 11), ('include', 11), ('waste', 11), ('chris', 11), ('telling', 11), ('views', 11), ('political', 11), ('accept', 11), ('sort', 11), ('losers', 11), ('anymore', 11), ('okay', 11), ('mazy', 11), ('raowfat', 11), ('genocide', 10), ('japan', 10), ('heck', 10), ('idiocy', 10), ('bag', 10), ('family', 10), ('started', 10), ('masturbation', 10), ('tv', 10), ('public', 10), ('filthy', 10), ('short', 10), ('bill', 10), ('experience', 10), ('accounts', 10)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(\"Sample_labaled_data.csv\")\n",
    "data = pd.DataFrame(data)\n",
    "print(data)\n",
    "\n",
    "toxic_labels = data[\"toxic\"].value_counts()\n",
    "print(toxic_labels)\n",
    "\n",
    "toxic_comments = data[data[\"toxic\"] == \"yes\"][\"comment_text\"].tolist()\n",
    "words = []\n",
    "for comment in toxic_comments:\n",
    "    words += re.findall(r'\\b\\w+\\b', comment.lower())\n",
    "word_counts = Counter(words)\n",
    "print(word_counts.most_common(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a06113",
   "metadata": {},
   "source": [
    "I am going to test the API with comments that were deemed toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ea75dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score: 0.7105462\n",
      "The comment is toxic.\n"
     ]
    }
   ],
   "source": [
    "API_KEY = 'AIzaSyDwOEmbZuVzQmampYmHqa2ZVs95vGegjmM'\n",
    "url = 'https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=' + API_KEY\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "comments = [\n",
    "    'Hey shithead stop vandilizing articles',\n",
    "    'Being drunk made Gibson say what he really believes The little freak is a Nazi like his father and I hope he dies of lung cancer Soon',\n",
    "    'where I feel like a man instead of an idiot',\n",
    "    'no hes not he have his own show whihc is a cheap copy of ragu romeo show and hes only popular because of stupid people who auditions and watch this gutter show'\n",
    "]\n",
    "\n",
    "for comment in comments:\n",
    "    data = {\n",
    "        'comment': {'text': comment},\n",
    "        'languages': ['en'],\n",
    "        'requestedAttributes': {'TOXICITY': {}},\n",
    "        'doNotStore': True\n",
    "    }\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "response_dict = response.json()\n",
    "toxicity_score = response_dict['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "print('Toxicity score:', toxicity_score)\n",
    "\n",
    "threshold = 0.5\n",
    "if toxicity_score > threshold:\n",
    "    print('The comment is toxic.')\n",
    "else:\n",
    "    print('The comment is not toxic.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac65c8",
   "metadata": {},
   "source": [
    "Now, I am going to test comments with the API that are non-toxic but can be deemed toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5147e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score: 0.14950264\n",
      "The comment is not toxic.\n"
     ]
    }
   ],
   "source": [
    "API_KEY = 'AIzaSyDwOEmbZuVzQmampYmHqa2ZVs95vGegjmM'\n",
    "url = 'https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key=' + API_KEY\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "comments = [\n",
    "    '  Ive removed the frivolous criticism section  ',\n",
    "    '  Think youre missing the point  David and Goliath as is commonly used in the English language refers to the Biblical legend  The clothing store should be a disambiguation link in the main article   ',\n",
    "    '   Thank you   James thank you for reverting that horrible vandalism from my user page   ',\n",
    "    '  I dont think he belongs in this category  of course he believed that the world was created by God   that much is obvious But so does an overwhelming majority of Orthodox Jews  that doesnt mean that every Orthodox Jew who has an article should be in this category I think that only people who are publicly and specifically outspoken about the issue of creation vs evolution I dont think the Rebbe was known for that  '\n",
    "]\n",
    "\n",
    "for comment in comments:\n",
    "    data = {\n",
    "        'comment': {'text': comment},\n",
    "        'languages': ['en'],\n",
    "        'requestedAttributes': {'TOXICITY': {}},\n",
    "        'doNotStore': True\n",
    "    }\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "response_dict = response.json()\n",
    "toxicity_score = response_dict['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "print('Toxicity score:', toxicity_score)\n",
    "\n",
    "threshold = 0.5\n",
    "if toxicity_score > threshold:\n",
    "    print('The comment is toxic.')\n",
    "else:\n",
    "    print('The comment is not toxic.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
